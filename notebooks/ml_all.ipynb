{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/62v23f191zsbtpgk23vhgv2h0000gn/T/ipykernel_59455/1274987493.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(\"../data/yellow_tripdata_2020-04.csv\", nrows=6000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 238073 entries, 0 to 238072\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   VendorID               238073 non-null  int64  \n",
      " 1   tpep_pickup_datetime   238073 non-null  object \n",
      " 2   tpep_dropoff_datetime  238073 non-null  object \n",
      " 3   passenger_count        218493 non-null  float64\n",
      " 4   trip_distance          238073 non-null  float64\n",
      " 5   RatecodeID             218493 non-null  float64\n",
      " 6   store_and_fwd_flag     218493 non-null  object \n",
      " 7   PULocationID           238073 non-null  int64  \n",
      " 8   DOLocationID           238073 non-null  int64  \n",
      " 9   payment_type           238073 non-null  int64  \n",
      " 10  fare_amount            238073 non-null  float64\n",
      " 11  extra                  238073 non-null  float64\n",
      " 12  mta_tax                238073 non-null  float64\n",
      " 13  tip_amount             238073 non-null  float64\n",
      " 14  tolls_amount           238073 non-null  float64\n",
      " 15  improvement_surcharge  238073 non-null  float64\n",
      " 16  total_amount           238073 non-null  float64\n",
      " 17  congestion_surcharge   218493 non-null  float64\n",
      " 18  airport_fee            0 non-null       float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 34.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# log regression\n",
    "# feature: start, end, day\n",
    "# result: duration\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"../data/yellow_tripdata_2020-04.csv\", nrows=6000000)\n",
    "\n",
    "train.info()\n",
    "train['tpep_pickup_datetime'] = pd.to_datetime(train['tpep_pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "train['tpep_dropoff_datetime'] = pd.to_datetime(train['tpep_dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "train['trip_duration'] = (train['tpep_dropoff_datetime'] - train['tpep_pickup_datetime']).dt.seconds\n",
    "train['PULocationID'].fillna(-1, inplace=True)\n",
    "train['DOLocationID'].fillna(-1, inplace=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "#X_train = train[['PULocationID', 'DOLocationID']]\n",
    "#y_train = train[['trip_duration']]\n",
    "#model_y = train[['total_amount']]\n",
    "#X_test = df_05[['PULocationID', 'DOLocationID']]\n",
    "#y_test = df_05[['trip_duration']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=train.drop([\"fare_amount\"],axis=1)\n",
    "y=train[\"fare_amount\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=123)#test_size is the proportion of data that is to be kept aside for validation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_train = X_train[['PULocationID','DOLocationID']]\n",
    "X_test = X_test[['PULocationID','DOLocationID']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basline RMSE of Validation data : 11.443153287956056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "avg_fare=round(np.mean(y_train),2) #11.31\n",
    "baseline_pred=np.repeat(avg_fare,y_test.shape[0])\n",
    "baseline_rmse=np.sqrt(mean_squared_error(baseline_pred, y_test))\n",
    "print(\"Basline RMSE of Validation data :\",baseline_rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE for Linear Regression is  11.398179107965786\n",
      "Train RMSE for Linear Regression is  11.785619201795623\n",
      "Variance for Linear Regression is  0.38744009382983613\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "y_pred=np.round(lm.predict(X_test),2)\n",
    "lm_rmse=np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "lm_train_rmse=np.sqrt(mean_squared_error(lm.predict(X_train), y_train))\n",
    "lm_variance=abs(lm_train_rmse - lm_rmse)\n",
    "print(\"Test RMSE for Linear Regression is \",lm_rmse)\n",
    "print(\"Train RMSE for Linear Regression is \",lm_train_rmse)\n",
    "print(\"Variance for Linear Regression is \",lm_variance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Random Forest is  6.955823172265283\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 883,n_jobs=-1)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred= rf.predict(X_test)\n",
    "rf_rmse=np.sqrt(mean_squared_error(rf_pred, y_test))\n",
    "print(\"RMSE for Random Forest is \",rf_rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenoc1/.conda/envs/taxi2/lib/python3.9/site-packages/lightgbm/engine.py:573: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kenoc1/.conda/envs/taxi2/lib/python3.9/site-packages/lightgbm/engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.152675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.251388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 11.634427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenoc1/.conda/envs/taxi2/lib/python3.9/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 11.660562\n",
      "[LightGBM] [Info] Start training from score 11.653872\n",
      "[LightGBM] [Info] Start training from score 11.664505\n",
      "[LightGBM] [Info] Start training from score 11.674088\n",
      "[LightGBM] [Info] Start training from score 11.663011\n",
      "[LightGBM] [Info] Start training from score 11.663297\n",
      "[LightGBM] [Info] Start training from score 11.666338\n",
      "[LightGBM] [Info] Start training from score 11.654494\n",
      "[LightGBM] [Info] Start training from score 11.671579\n",
      "[20]\tcv_agg's rmse: 9.96166 + 0.714707\n",
      "[40]\tcv_agg's rmse: 9.58573 + 0.722929\n",
      "[60]\tcv_agg's rmse: 9.37474 + 0.738957\n",
      "[80]\tcv_agg's rmse: 9.22168 + 0.750375\n",
      "[100]\tcv_agg's rmse: 9.10347 + 0.756657\n",
      "[120]\tcv_agg's rmse: 9.01345 + 0.764549\n",
      "[140]\tcv_agg's rmse: 8.93757 + 0.767932\n",
      "[160]\tcv_agg's rmse: 8.86325 + 0.770781\n",
      "[180]\tcv_agg's rmse: 8.80171 + 0.77193\n",
      "[200]\tcv_agg's rmse: 8.74453 + 0.76814\n",
      "[220]\tcv_agg's rmse: 8.69523 + 0.77063\n",
      "[240]\tcv_agg's rmse: 8.65296 + 0.772102\n",
      "[260]\tcv_agg's rmse: 8.61335 + 0.776143\n",
      "[280]\tcv_agg's rmse: 8.57723 + 0.778122\n",
      "[300]\tcv_agg's rmse: 8.54847 + 0.778973\n",
      "[320]\tcv_agg's rmse: 8.51833 + 0.782361\n",
      "[340]\tcv_agg's rmse: 8.49366 + 0.783309\n",
      "[360]\tcv_agg's rmse: 8.46606 + 0.785083\n",
      "[380]\tcv_agg's rmse: 8.44423 + 0.784113\n",
      "[400]\tcv_agg's rmse: 8.42543 + 0.784521\n",
      "[420]\tcv_agg's rmse: 8.4078 + 0.784122\n",
      "[440]\tcv_agg's rmse: 8.38627 + 0.784898\n",
      "[460]\tcv_agg's rmse: 8.36946 + 0.78808\n",
      "[480]\tcv_agg's rmse: 8.35306 + 0.789715\n",
      "[500]\tcv_agg's rmse: 8.34022 + 0.791349\n",
      "[520]\tcv_agg's rmse: 8.32558 + 0.79065\n",
      "[540]\tcv_agg's rmse: 8.3126 + 0.792441\n",
      "[560]\tcv_agg's rmse: 8.30166 + 0.791651\n",
      "[580]\tcv_agg's rmse: 8.28876 + 0.792765\n",
      "[600]\tcv_agg's rmse: 8.2772 + 0.793315\n",
      "[620]\tcv_agg's rmse: 8.26646 + 0.79409\n",
      "[640]\tcv_agg's rmse: 8.25512 + 0.794133\n",
      "[660]\tcv_agg's rmse: 8.24636 + 0.796724\n",
      "[680]\tcv_agg's rmse: 8.23585 + 0.797135\n",
      "[700]\tcv_agg's rmse: 8.22545 + 0.798213\n",
      "[720]\tcv_agg's rmse: 8.21659 + 0.798465\n",
      "[740]\tcv_agg's rmse: 8.20838 + 0.797775\n",
      "[760]\tcv_agg's rmse: 8.20025 + 0.798863\n",
      "[780]\tcv_agg's rmse: 8.19354 + 0.800628\n",
      "[800]\tcv_agg's rmse: 8.18385 + 0.800756\n",
      "[820]\tcv_agg's rmse: 8.17678 + 0.80119\n",
      "[840]\tcv_agg's rmse: 8.17 + 0.801549\n",
      "[860]\tcv_agg's rmse: 8.16405 + 0.801165\n",
      "[880]\tcv_agg's rmse: 8.15835 + 0.800885\n",
      "[900]\tcv_agg's rmse: 8.15221 + 0.800544\n",
      "[920]\tcv_agg's rmse: 8.14695 + 0.80088\n",
      "[940]\tcv_agg's rmse: 8.14158 + 0.800834\n",
      "[960]\tcv_agg's rmse: 8.13594 + 0.801034\n",
      "[980]\tcv_agg's rmse: 8.13021 + 0.800262\n",
      "[1000]\tcv_agg's rmse: 8.12679 + 0.800646\n",
      "[1020]\tcv_agg's rmse: 8.12163 + 0.801908\n",
      "[1040]\tcv_agg's rmse: 8.11683 + 0.803453\n",
      "[1060]\tcv_agg's rmse: 8.11324 + 0.802865\n",
      "[1080]\tcv_agg's rmse: 8.11007 + 0.802612\n",
      "[1100]\tcv_agg's rmse: 8.10587 + 0.802109\n",
      "[1120]\tcv_agg's rmse: 8.1014 + 0.80204\n",
      "[1140]\tcv_agg's rmse: 8.09786 + 0.802697\n",
      "[1160]\tcv_agg's rmse: 8.09496 + 0.802882\n",
      "[1180]\tcv_agg's rmse: 8.09204 + 0.80352\n",
      "[1200]\tcv_agg's rmse: 8.0881 + 0.804181\n",
      "[1220]\tcv_agg's rmse: 8.08488 + 0.804624\n",
      "[1240]\tcv_agg's rmse: 8.08118 + 0.803938\n",
      "[1260]\tcv_agg's rmse: 8.0785 + 0.804063\n",
      "[1280]\tcv_agg's rmse: 8.07588 + 0.804949\n",
      "[1300]\tcv_agg's rmse: 8.07389 + 0.80526\n",
      "[1320]\tcv_agg's rmse: 8.07171 + 0.80622\n",
      "[1340]\tcv_agg's rmse: 8.06975 + 0.806589\n",
      "[1360]\tcv_agg's rmse: 8.06765 + 0.807879\n",
      "[1380]\tcv_agg's rmse: 8.06521 + 0.807104\n",
      "[1400]\tcv_agg's rmse: 8.06288 + 0.807582\n",
      "[1420]\tcv_agg's rmse: 8.06036 + 0.807787\n",
      "[1440]\tcv_agg's rmse: 8.05799 + 0.807632\n",
      "[1460]\tcv_agg's rmse: 8.05663 + 0.80705\n",
      "[1480]\tcv_agg's rmse: 8.05461 + 0.807256\n",
      "[1500]\tcv_agg's rmse: 8.05213 + 0.807359\n",
      "[1520]\tcv_agg's rmse: 8.0501 + 0.806482\n",
      "[1540]\tcv_agg's rmse: 8.04795 + 0.806683\n",
      "[1560]\tcv_agg's rmse: 8.04579 + 0.806887\n",
      "[1580]\tcv_agg's rmse: 8.04372 + 0.806776\n",
      "[1600]\tcv_agg's rmse: 8.04222 + 0.806035\n",
      "[1620]\tcv_agg's rmse: 8.04028 + 0.8065\n",
      "[1640]\tcv_agg's rmse: 8.03882 + 0.806793\n",
      "[1660]\tcv_agg's rmse: 8.03664 + 0.807317\n",
      "[1680]\tcv_agg's rmse: 8.03469 + 0.807609\n",
      "[1700]\tcv_agg's rmse: 8.03317 + 0.807262\n",
      "[1720]\tcv_agg's rmse: 8.03095 + 0.80738\n",
      "[1740]\tcv_agg's rmse: 8.02953 + 0.807567\n",
      "[1760]\tcv_agg's rmse: 8.02822 + 0.807403\n",
      "[1780]\tcv_agg's rmse: 8.02671 + 0.807394\n",
      "[1800]\tcv_agg's rmse: 8.02516 + 0.807264\n",
      "[1820]\tcv_agg's rmse: 8.02368 + 0.806837\n",
      "[1840]\tcv_agg's rmse: 8.02261 + 0.806802\n",
      "[1860]\tcv_agg's rmse: 8.0199 + 0.806962\n",
      "[1880]\tcv_agg's rmse: 8.01842 + 0.80659\n",
      "[1900]\tcv_agg's rmse: 8.01735 + 0.806855\n",
      "[1920]\tcv_agg's rmse: 8.01643 + 0.806714\n",
      "[1940]\tcv_agg's rmse: 8.01492 + 0.806627\n",
      "[1960]\tcv_agg's rmse: 8.0135 + 0.807393\n",
      "[1980]\tcv_agg's rmse: 8.01207 + 0.807396\n",
      "[2000]\tcv_agg's rmse: 8.01045 + 0.807683\n",
      "[2020]\tcv_agg's rmse: 8.009 + 0.807693\n",
      "[2040]\tcv_agg's rmse: 8.00824 + 0.807524\n",
      "[2060]\tcv_agg's rmse: 8.00728 + 0.807066\n",
      "[2080]\tcv_agg's rmse: 8.0055 + 0.80742\n",
      "[2100]\tcv_agg's rmse: 8.0037 + 0.807148\n",
      "[2120]\tcv_agg's rmse: 8.00189 + 0.807443\n",
      "[2140]\tcv_agg's rmse: 8.00013 + 0.808278\n",
      "[2160]\tcv_agg's rmse: 7.99856 + 0.808474\n",
      "[2180]\tcv_agg's rmse: 7.99697 + 0.808702\n",
      "[2200]\tcv_agg's rmse: 7.99564 + 0.809133\n",
      "[2220]\tcv_agg's rmse: 7.99397 + 0.809028\n",
      "[2240]\tcv_agg's rmse: 7.99339 + 0.809356\n",
      "[2260]\tcv_agg's rmse: 7.99246 + 0.810134\n",
      "[2280]\tcv_agg's rmse: 7.99132 + 0.809937\n",
      "[2300]\tcv_agg's rmse: 7.99058 + 0.810036\n",
      "[2320]\tcv_agg's rmse: 7.98907 + 0.809993\n",
      "[2340]\tcv_agg's rmse: 7.98804 + 0.809759\n",
      "[2360]\tcv_agg's rmse: 7.98659 + 0.810046\n",
      "[2380]\tcv_agg's rmse: 7.98546 + 0.81028\n",
      "[2400]\tcv_agg's rmse: 7.98456 + 0.810142\n",
      "[2420]\tcv_agg's rmse: 7.98346 + 0.810081\n",
      "[2440]\tcv_agg's rmse: 7.98206 + 0.810889\n",
      "[2460]\tcv_agg's rmse: 7.98105 + 0.810712\n",
      "[2480]\tcv_agg's rmse: 7.98061 + 0.810785\n",
      "[2500]\tcv_agg's rmse: 7.97951 + 0.810827\n",
      "[2520]\tcv_agg's rmse: 7.97919 + 0.81058\n",
      "[2540]\tcv_agg's rmse: 7.97885 + 0.810589\n",
      "[2560]\tcv_agg's rmse: 7.97815 + 0.810705\n",
      "[2580]\tcv_agg's rmse: 7.97687 + 0.811209\n",
      "[2600]\tcv_agg's rmse: 7.97635 + 0.811247\n",
      "[2620]\tcv_agg's rmse: 7.97558 + 0.811291\n",
      "[2640]\tcv_agg's rmse: 7.97532 + 0.811217\n",
      "[2660]\tcv_agg's rmse: 7.97507 + 0.810886\n",
      "[2680]\tcv_agg's rmse: 7.97382 + 0.811445\n",
      "[2700]\tcv_agg's rmse: 7.97292 + 0.811623\n",
      "[2720]\tcv_agg's rmse: 7.97222 + 0.811521\n",
      "[2740]\tcv_agg's rmse: 7.97122 + 0.811118\n",
      "[2760]\tcv_agg's rmse: 7.97012 + 0.811262\n",
      "[2780]\tcv_agg's rmse: 7.96927 + 0.811305\n",
      "[2800]\tcv_agg's rmse: 7.96866 + 0.811348\n",
      "[2820]\tcv_agg's rmse: 7.96779 + 0.811412\n",
      "[2840]\tcv_agg's rmse: 7.96711 + 0.811677\n",
      "[2860]\tcv_agg's rmse: 7.96628 + 0.811819\n",
      "[2880]\tcv_agg's rmse: 7.96532 + 0.812075\n",
      "[2900]\tcv_agg's rmse: 7.96475 + 0.812183\n",
      "[2920]\tcv_agg's rmse: 7.96373 + 0.812169\n",
      "[2940]\tcv_agg's rmse: 7.96265 + 0.812147\n",
      "[2960]\tcv_agg's rmse: 7.96172 + 0.811748\n",
      "[2980]\tcv_agg's rmse: 7.96061 + 0.811558\n",
      "[3000]\tcv_agg's rmse: 7.95943 + 0.810897\n",
      "[3020]\tcv_agg's rmse: 7.95868 + 0.810553\n",
      "[3040]\tcv_agg's rmse: 7.95744 + 0.81039\n",
      "[3060]\tcv_agg's rmse: 7.95642 + 0.810184\n",
      "[3080]\tcv_agg's rmse: 7.95581 + 0.810151\n",
      "[3100]\tcv_agg's rmse: 7.95519 + 0.809685\n",
      "[3120]\tcv_agg's rmse: 7.95399 + 0.809174\n",
      "[3140]\tcv_agg's rmse: 7.95296 + 0.809045\n",
      "[3160]\tcv_agg's rmse: 7.95271 + 0.809192\n",
      "[3180]\tcv_agg's rmse: 7.9519 + 0.809346\n",
      "[3200]\tcv_agg's rmse: 7.95139 + 0.809699\n",
      "[3220]\tcv_agg's rmse: 7.95056 + 0.809191\n",
      "[3240]\tcv_agg's rmse: 7.94981 + 0.809161\n",
      "[3260]\tcv_agg's rmse: 7.94966 + 0.809645\n",
      "[3280]\tcv_agg's rmse: 7.94865 + 0.809455\n",
      "[3300]\tcv_agg's rmse: 7.94785 + 0.809631\n",
      "[3320]\tcv_agg's rmse: 7.94796 + 0.809239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenoc1/.conda/envs/taxi2/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 417\n",
      "[LightGBM] [Info] Number of data points in the train set: 178554, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 11.660754\n",
      "RMSE for Light GBM is  7.170031094221064\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_data=lgb.Dataset(X_train,label=y_train)\n",
    "param = {'num_leaves':31, 'num_trees':5000,'objective':'regression'}\n",
    "param['metric'] = 'l2_root'\n",
    "num_round=5000\n",
    "cv_results = lgb.cv(param, train_data, num_boost_round=num_round, nfold=10,verbose_eval=20, early_stopping_rounds=20,stratified=False)\n",
    "lgb_bst=lgb.train(param,train_data,len(cv_results['rmse-mean']))\n",
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \",lgb_rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}