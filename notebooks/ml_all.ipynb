{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/62v23f191zsbtpgk23vhgv2h0000gn/T/ipykernel_59455/814977998.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(\"../data/yellow_tripdata_2020-04.csv\", nrows=6000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 238073 entries, 0 to 238072\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   VendorID               238073 non-null  int64  \n",
      " 1   tpep_pickup_datetime   238073 non-null  object \n",
      " 2   tpep_dropoff_datetime  238073 non-null  object \n",
      " 3   passenger_count        218493 non-null  float64\n",
      " 4   trip_distance          238073 non-null  float64\n",
      " 5   RatecodeID             218493 non-null  float64\n",
      " 6   store_and_fwd_flag     218493 non-null  object \n",
      " 7   PULocationID           238073 non-null  int64  \n",
      " 8   DOLocationID           238073 non-null  int64  \n",
      " 9   payment_type           238073 non-null  int64  \n",
      " 10  fare_amount            238073 non-null  float64\n",
      " 11  extra                  238073 non-null  float64\n",
      " 12  mta_tax                238073 non-null  float64\n",
      " 13  tip_amount             238073 non-null  float64\n",
      " 14  tolls_amount           238073 non-null  float64\n",
      " 15  improvement_surcharge  238073 non-null  float64\n",
      " 16  total_amount           238073 non-null  float64\n",
      " 17  congestion_surcharge   218493 non-null  float64\n",
      " 18  airport_fee            0 non-null       float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 34.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "        VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n0              1  2020-04-01 00:41:22   2020-04-01 01:01:53              1.0   \n1              1  2020-04-01 00:56:00   2020-04-01 01:09:25              1.0   \n2              1  2020-04-01 00:00:26   2020-04-01 00:09:25              1.0   \n3              1  2020-04-01 00:24:38   2020-04-01 00:34:38              0.0   \n4              2  2020-04-01 00:13:24   2020-04-01 00:18:26              1.0   \n...          ...                  ...                   ...              ...   \n238068         2  2020-04-30 23:30:00   2020-04-30 23:39:00              NaN   \n238069         2  2020-04-30 23:44:00   2020-04-30 23:54:00              NaN   \n238070         2  2020-04-30 23:25:00   2020-04-30 23:38:00              NaN   \n238071         2  2020-04-30 23:50:26   2020-05-01 00:28:21              NaN   \n238072         2  2020-04-30 23:16:47   2020-04-30 23:31:08              NaN   \n\n        trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n0                1.20         1.0                  N            41   \n1                3.40         1.0                  N            95   \n2                2.80         1.0                  N           237   \n3                2.60         1.0                  N            68   \n4                1.44         1.0                  Y           263   \n...               ...         ...                ...           ...   \n238068           2.02         NaN                NaN           238   \n238069           3.30         NaN                NaN           263   \n238070           6.40         NaN                NaN           137   \n238071          25.70         NaN                NaN            29   \n238072           5.63         NaN                NaN            14   \n\n        DOLocationID  payment_type  ...  tpep_pickup_month  \\\n0                 24             2  ...                  4   \n1                197             1  ...                  4   \n2                137             1  ...                  4   \n3                142             1  ...                  4   \n4                 74             1  ...                  4   \n...              ...           ...  ...                ...   \n238068            75             0  ...                  4   \n238069           230             0  ...                  4   \n238070            42             0  ...                  4   \n238071            69             0  ...                  4   \n238072            29             0  ...                  4   \n\n        tpep_dropoff_month  tpep_pickup_day_numeric  tpep_dropoff_day_numeric  \\\n0                        4                        1                         1   \n1                        4                        1                         1   \n2                        4                        1                         1   \n3                        4                        1                         1   \n4                        4                        1                         1   \n...                    ...                      ...                       ...   \n238068                   4                       30                        30   \n238069                   4                       30                        30   \n238070                   4                       30                        30   \n238071                   5                       30                         1   \n238072                   4                       30                        30   \n\n        tpep_pickup_day_name  tpep_dropoff_day_name  tpep_pickup_hour  \\\n0                  Wednesday              Wednesday                 0   \n1                  Wednesday              Wednesday                 0   \n2                  Wednesday              Wednesday                 0   \n3                  Wednesday              Wednesday                 0   \n4                  Wednesday              Wednesday                 0   \n...                      ...                    ...               ...   \n238068              Thursday               Thursday                23   \n238069              Thursday               Thursday                23   \n238070              Thursday               Thursday                23   \n238071              Thursday                 Friday                23   \n238072              Thursday               Thursday                23   \n\n        tpep_dropoff_hour  tpep_pickup_day  tpep_dropoff_day  \n0                       1                3                 3  \n1                       1                3                 3  \n2                       0                3                 3  \n3                       0                3                 3  \n4                       0                3                 3  \n...                   ...              ...               ...  \n238068                 23                4                 4  \n238069                 23                4                 4  \n238070                 23                4                 4  \n238071                  0                4                 5  \n238072                 23                4                 4  \n\n[238073 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VendorID</th>\n      <th>tpep_pickup_datetime</th>\n      <th>tpep_dropoff_datetime</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>RatecodeID</th>\n      <th>store_and_fwd_flag</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>payment_type</th>\n      <th>...</th>\n      <th>tpep_pickup_month</th>\n      <th>tpep_dropoff_month</th>\n      <th>tpep_pickup_day_numeric</th>\n      <th>tpep_dropoff_day_numeric</th>\n      <th>tpep_pickup_day_name</th>\n      <th>tpep_dropoff_day_name</th>\n      <th>tpep_pickup_hour</th>\n      <th>tpep_dropoff_hour</th>\n      <th>tpep_pickup_day</th>\n      <th>tpep_dropoff_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020-04-01 00:41:22</td>\n      <td>2020-04-01 01:01:53</td>\n      <td>1.0</td>\n      <td>1.20</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>41</td>\n      <td>24</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Wednesday</td>\n      <td>Wednesday</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-04-01 00:56:00</td>\n      <td>2020-04-01 01:09:25</td>\n      <td>1.0</td>\n      <td>3.40</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>95</td>\n      <td>197</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Wednesday</td>\n      <td>Wednesday</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2020-04-01 00:00:26</td>\n      <td>2020-04-01 00:09:25</td>\n      <td>1.0</td>\n      <td>2.80</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>237</td>\n      <td>137</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Wednesday</td>\n      <td>Wednesday</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2020-04-01 00:24:38</td>\n      <td>2020-04-01 00:34:38</td>\n      <td>0.0</td>\n      <td>2.60</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>68</td>\n      <td>142</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Wednesday</td>\n      <td>Wednesday</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2020-04-01 00:13:24</td>\n      <td>2020-04-01 00:18:26</td>\n      <td>1.0</td>\n      <td>1.44</td>\n      <td>1.0</td>\n      <td>Y</td>\n      <td>263</td>\n      <td>74</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Wednesday</td>\n      <td>Wednesday</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>238068</th>\n      <td>2</td>\n      <td>2020-04-30 23:30:00</td>\n      <td>2020-04-30 23:39:00</td>\n      <td>NaN</td>\n      <td>2.02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>238</td>\n      <td>75</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>30</td>\n      <td>30</td>\n      <td>Thursday</td>\n      <td>Thursday</td>\n      <td>23</td>\n      <td>23</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>238069</th>\n      <td>2</td>\n      <td>2020-04-30 23:44:00</td>\n      <td>2020-04-30 23:54:00</td>\n      <td>NaN</td>\n      <td>3.30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>263</td>\n      <td>230</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>30</td>\n      <td>30</td>\n      <td>Thursday</td>\n      <td>Thursday</td>\n      <td>23</td>\n      <td>23</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>238070</th>\n      <td>2</td>\n      <td>2020-04-30 23:25:00</td>\n      <td>2020-04-30 23:38:00</td>\n      <td>NaN</td>\n      <td>6.40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>137</td>\n      <td>42</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>30</td>\n      <td>30</td>\n      <td>Thursday</td>\n      <td>Thursday</td>\n      <td>23</td>\n      <td>23</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>238071</th>\n      <td>2</td>\n      <td>2020-04-30 23:50:26</td>\n      <td>2020-05-01 00:28:21</td>\n      <td>NaN</td>\n      <td>25.70</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29</td>\n      <td>69</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>30</td>\n      <td>1</td>\n      <td>Thursday</td>\n      <td>Friday</td>\n      <td>23</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>238072</th>\n      <td>2</td>\n      <td>2020-04-30 23:16:47</td>\n      <td>2020-04-30 23:31:08</td>\n      <td>NaN</td>\n      <td>5.63</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>29</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>30</td>\n      <td>30</td>\n      <td>Thursday</td>\n      <td>Thursday</td>\n      <td>23</td>\n      <td>23</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>238073 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log regression\n",
    "# feature: start, end, day\n",
    "# result: duration\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"../data/yellow_tripdata_2020-04.csv\", nrows=6000000)\n",
    "\n",
    "train.info()\n",
    "train['tpep_pickup_datetime'] = pd.to_datetime(train['tpep_pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "train['tpep_dropoff_datetime'] = pd.to_datetime(train['tpep_dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "train['trip_duration'] = (train['tpep_dropoff_datetime'] - train['tpep_pickup_datetime']).dt.seconds\n",
    "train['PULocationID'].fillna(-1, inplace=True)\n",
    "train['DOLocationID'].fillna(-1, inplace=True)\n",
    "\n",
    "train['tpep_pickup_month'] = train['tpep_pickup_datetime'].dt.month\n",
    "train['tpep_dropoff_month'] = train['tpep_dropoff_datetime'].dt.month\n",
    "train['tpep_pickup_day_numeric'] = train['tpep_pickup_datetime'].dt.day\n",
    "train['tpep_dropoff_day_numeric'] = train['tpep_dropoff_datetime'].dt.day\n",
    "train['tpep_pickup_day_name'] = train['tpep_pickup_datetime'].dt.day_name()\n",
    "train['tpep_dropoff_day_name'] = train['tpep_dropoff_datetime'].dt.day_name()\n",
    "train['tpep_pickup_hour'] = train['tpep_pickup_datetime'].dt.hour\n",
    "train['tpep_dropoff_hour'] = train['tpep_dropoff_datetime'].dt.hour\n",
    "train['tpep_pickup_day'] = train['tpep_pickup_datetime'].dt.strftime(\"%w\").astype(int)\n",
    "train['tpep_dropoff_day'] = train['tpep_dropoff_datetime'].dt.strftime(\"%w\").astype(int)\n",
    "\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop([\"fare_amount\"], axis=1)\n",
    "y = train[\"fare_amount\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "X_train = X_train[['PULocationID', 'DOLocationID', 'tpep_pickup_month', 'tpep_pickup_day', 'tpep_pickup_hour']]\n",
    "X_test = X_test[['PULocationID', 'DOLocationID', 'tpep_pickup_month', 'tpep_pickup_day', 'tpep_pickup_hour']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basline RMSE of Validation data : 11.443153287956056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "avg_fare = round(np.mean(y_train), 2)\n",
    "baseline_pred = np.repeat(avg_fare, y_test.shape[0])\n",
    "baseline_rmse = np.sqrt(mean_squared_error(baseline_pred, y_test))\n",
    "print(\"Basline RMSE of Validation data :\", baseline_rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE for Linear Regression is  11.396643558887861\n",
      "Train RMSE for Linear Regression is  11.781743473379455\n",
      "Variance for Linear Regression is  0.38509991449159386\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = np.round(lm.predict(X_test), 2)\n",
    "lm_rmse = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "lm_train_rmse = np.sqrt(mean_squared_error(lm.predict(X_train), y_train))\n",
    "lm_variance = abs(lm_train_rmse - lm_rmse)\n",
    "print(\"Test RMSE for Linear Regression is \", lm_rmse)\n",
    "print(\"Train RMSE for Linear Regression is \", lm_train_rmse)\n",
    "print(\"Variance for Linear Regression is \", lm_variance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Random Forest is  7.482095927610649\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=883, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_rmse = np.sqrt(mean_squared_error(rf_pred, y_test))\n",
    "print(\"RMSE for Random Forest is \", rf_rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenoc1/.conda/envs/taxi2/lib/python3.9/site-packages/lightgbm/engine.py:573: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kenoc1/.conda/envs/taxi2/lib/python3.9/site-packages/lightgbm/engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 160695, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 11.634427\n",
      "[LightGBM] [Info] Start training from score 11.660562\n",
      "[LightGBM] [Info] Start training from score 11.653872\n",
      "[LightGBM] [Info] Start training from score 11.664505\n",
      "[LightGBM] [Info] Start training from score 11.674088\n",
      "[LightGBM] [Info] Start training from score 11.663011\n",
      "[LightGBM] [Info] Start training from score 11.663297\n",
      "[LightGBM] [Info] Start training from score 11.666338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenoc1/.conda/envs/taxi2/lib/python3.9/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 11.654494\n",
      "[LightGBM] [Info] Start training from score 11.671579\n",
      "[20]\tcv_agg's rmse: 10.0128 + 0.700431\n",
      "[40]\tcv_agg's rmse: 9.63526 + 0.731158\n",
      "[60]\tcv_agg's rmse: 9.4306 + 0.737494\n",
      "[80]\tcv_agg's rmse: 9.28397 + 0.74763\n",
      "[100]\tcv_agg's rmse: 9.17419 + 0.754623\n",
      "[120]\tcv_agg's rmse: 9.10296 + 0.761966\n",
      "[140]\tcv_agg's rmse: 9.0418 + 0.762081\n",
      "[160]\tcv_agg's rmse: 8.98755 + 0.766219\n",
      "[180]\tcv_agg's rmse: 8.93554 + 0.769806\n",
      "[200]\tcv_agg's rmse: 8.89103 + 0.77386\n",
      "[220]\tcv_agg's rmse: 8.84857 + 0.773438\n",
      "[240]\tcv_agg's rmse: 8.81117 + 0.775543\n",
      "[260]\tcv_agg's rmse: 8.77849 + 0.782038\n",
      "[280]\tcv_agg's rmse: 8.74711 + 0.78437\n",
      "[300]\tcv_agg's rmse: 8.71871 + 0.784278\n",
      "[320]\tcv_agg's rmse: 8.69812 + 0.78405\n",
      "[340]\tcv_agg's rmse: 8.67522 + 0.782848\n",
      "[360]\tcv_agg's rmse: 8.65348 + 0.780715\n",
      "[380]\tcv_agg's rmse: 8.6337 + 0.783345\n",
      "[400]\tcv_agg's rmse: 8.61796 + 0.786183\n",
      "[420]\tcv_agg's rmse: 8.602 + 0.786867\n",
      "[440]\tcv_agg's rmse: 8.58746 + 0.788638\n",
      "[460]\tcv_agg's rmse: 8.57384 + 0.788826\n",
      "[480]\tcv_agg's rmse: 8.55824 + 0.788283\n",
      "[500]\tcv_agg's rmse: 8.54215 + 0.78848\n",
      "[520]\tcv_agg's rmse: 8.52947 + 0.790485\n",
      "[540]\tcv_agg's rmse: 8.51995 + 0.790251\n",
      "[560]\tcv_agg's rmse: 8.50611 + 0.791163\n",
      "[580]\tcv_agg's rmse: 8.49625 + 0.792764\n",
      "[600]\tcv_agg's rmse: 8.48488 + 0.792773\n",
      "[620]\tcv_agg's rmse: 8.47425 + 0.795876\n",
      "[640]\tcv_agg's rmse: 8.46823 + 0.798966\n",
      "[660]\tcv_agg's rmse: 8.46057 + 0.800392\n",
      "[680]\tcv_agg's rmse: 8.45205 + 0.800251\n",
      "[700]\tcv_agg's rmse: 8.44442 + 0.801641\n",
      "[720]\tcv_agg's rmse: 8.43833 + 0.801346\n",
      "[740]\tcv_agg's rmse: 8.43474 + 0.801977\n",
      "[760]\tcv_agg's rmse: 8.42866 + 0.802135\n",
      "[780]\tcv_agg's rmse: 8.42256 + 0.801886\n",
      "[800]\tcv_agg's rmse: 8.41594 + 0.802598\n",
      "[820]\tcv_agg's rmse: 8.40927 + 0.803088\n",
      "[840]\tcv_agg's rmse: 8.4031 + 0.804904\n",
      "[860]\tcv_agg's rmse: 8.39584 + 0.805593\n",
      "[880]\tcv_agg's rmse: 8.39232 + 0.807527\n",
      "[900]\tcv_agg's rmse: 8.38871 + 0.806963\n",
      "[920]\tcv_agg's rmse: 8.3855 + 0.805999\n",
      "[940]\tcv_agg's rmse: 8.38153 + 0.804289\n",
      "[960]\tcv_agg's rmse: 8.37908 + 0.802951\n",
      "[980]\tcv_agg's rmse: 8.37538 + 0.803732\n",
      "[1000]\tcv_agg's rmse: 8.37227 + 0.805254\n",
      "[1020]\tcv_agg's rmse: 8.36992 + 0.806006\n",
      "[1040]\tcv_agg's rmse: 8.36743 + 0.804261\n",
      "[1060]\tcv_agg's rmse: 8.36613 + 0.804061\n",
      "[1080]\tcv_agg's rmse: 8.3627 + 0.804425\n",
      "[1100]\tcv_agg's rmse: 8.36085 + 0.803972\n",
      "[1120]\tcv_agg's rmse: 8.3586 + 0.803855\n",
      "[1140]\tcv_agg's rmse: 8.35422 + 0.805124\n",
      "[1160]\tcv_agg's rmse: 8.35275 + 0.805709\n",
      "[1180]\tcv_agg's rmse: 8.3493 + 0.806989\n",
      "[1200]\tcv_agg's rmse: 8.34534 + 0.807619\n",
      "[1220]\tcv_agg's rmse: 8.34469 + 0.80678\n",
      "[1240]\tcv_agg's rmse: 8.34429 + 0.805566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenoc1/.conda/envs/taxi2/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 452\n",
      "[LightGBM] [Info] Number of data points in the train set: 178554, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 11.660754\n",
      "RMSE for Light GBM is  7.5119101475383765\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "param = {'num_leaves': 31, 'num_trees': 5000, 'objective': 'regression'}\n",
    "param['metric'] = 'l2_root'\n",
    "num_round = 5000\n",
    "cv_results = lgb.cv(param, train_data, num_boost_round=num_round, nfold=10, verbose_eval=20, early_stopping_rounds=20,\n",
    "                    stratified=False)\n",
    "lgb_bst = lgb.train(param, train_data, len(cv_results['rmse-mean']))\n",
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse = np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \", lgb_rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:  [12.49]\n",
      "Random Forest:  [13.12443333]\n",
      "LightGBM:  [16.86687947]\n"
     ]
    }
   ],
   "source": [
    "# testing 1 dataset\n",
    "df_test = pd.DataFrame([[107, 87, 4, 6, 14]], columns=['PULocationID', 'DOLocationID', 'tpep_pickup_month', 'tpep_pickup_day', 'tpep_pickup_hour'])\n",
    "\n",
    "y_test_pred = np.round(lm.predict(df_test), 2)\n",
    "rf_test_pred = rf.predict(df_test)\n",
    "lgb_test_pred = lgb_bst.predict(df_test)\n",
    "#print(df_test)\n",
    "print(\"Linear Regression: \", y_test_pred)\n",
    "print(\"Random Forest: \", rf_test_pred)\n",
    "print(\"LightGBM: \", lgb_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}